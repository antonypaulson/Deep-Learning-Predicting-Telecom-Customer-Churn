# -*- coding: utf-8 -*-
"""Churn Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1myK3tY31coZB0ZSae7SNEouGh32Kk0cd
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython import display
from matplotlib import cm
from matplotlib import gridspec
from tensorflow.python.data import Dataset
from tensorflow import keras

tf.logging.set_verbosity(tf.logging.ERROR)
pd.options.display.max_rows =5
pd.options.display.float_format = '{:.2f}'.format
churn_df = pd.read_csv('churn.csv', sep = ',')
churn_df = churn_df.reindex(np.random.permutation(churn_df.index))

churn_df.dtypes

def preprocess(churn_df):
  select_features = churn_df[['gender','SeniorCitizen','Partner','Dependents','PhoneService','MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','Contract','PaperlessBilling','PaymentMethod']]
  for i in range(16):
    select_features[list(select_features)[i]] = select_features[list(select_features)[i]].astype('category')
  cat_columns =select_features.select_dtypes(['category']).columns
  process_features = pd.get_dummies(select_features[cat_columns], drop_first=True)
  process_features[['tenure','MonthlyCharges','TotalCharges']] = churn_df[['tenure','MonthlyCharges','TotalCharges']]
  process_features['TotalCharges'] = pd.to_numeric(process_features.TotalCharges, errors = 'coerce')
  process_features["TotalCharges"] = process_features['TotalCharges'].fillna(method = 'ffill')
  return process_features

def preprocess_target(churn_df):
  output_targets = churn_df[['Churn']]
  i=0
  output_targets[list(output_targets)[i]]=output_targets[list(output_targets)[i]].astype('category')
  cat=output_targets.select_dtypes(['category']).columns
  output_targets=pd.get_dummies(output_targets[cat],drop_first=True)
  return output_targets

#Training Data
training_sample = preprocess(churn_df.head(5000))
training_target = preprocess_target(churn_df.head(5000))

#Validation Data
validation_sample = preprocess(churn_df.head(2043))
validation_target = preprocess_target(churn_df.head(2043))

print ("Training example summary:")
display.display(training_sample.describe())

print('Validation example summary: ')
display.display(validation_sample.describe())

print('Training target summary:')
display.display(training_target.describe())

print ('Validation Target summary:')
display.display(validation_target.describe())

# Now this is where Keras the mighty comes in

model = keras.Sequential([
    keras.layers.Dense(64, activation = tf.nn.relu,
                      input_shape = (training_sample.shape[1],)),
    keras.layers.Dense(64, activation = tf.nn.sigmoid),
    keras.layers.Dense(1)
])

rms_optimizer = tf.train.AdamOptimizer()

#The loss is the mean square error and the metric used is the mean absolute error
model.compile(loss='binary_crossentropy',
             optimizer = rms_optimizer,
             metrics = ['accuracy'])

model.summary()

#To check whether our model runs
class Dot(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs):
    if epoch % 100 == 0 : print('')
    print ('.', end='')
    
set_epoch = 5
tf.set_random_seed(1)

# Store training stats
fitting = model.fit(training_sample, training_target, epochs = set_epoch,
                   validation_split =0.2, verbose = 0,
                   callbacks=[Dot()])

print(fitting.history)

#Plotting the model

import matplotlib.pyplot as plt
def plot_history(history):
  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('MAE in 1000')
  plt.plot(history.epoch, np.array(history.history['acc']), label = 'training_accuracy')
  plt.plot(history.epoch, np.array(history.history['val_acc']), label = 'Validation_accuracy')
  plt.legend()
  plt.xlim([0,100])
plot_history(fitting)

